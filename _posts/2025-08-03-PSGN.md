---
title: "PSGN"
date: 2025-08-03 17:30:00 +0900   # ISO 8601 형식 권장
categories: [Blog, Tutorial]      # 상위/하위 카테고리 배열
tags: [Jekyll, Chirpy, GitHub Pages]  # 태그는 자유롭게
image:
  src: /assets/img/sample/cover.jpg   # 포스트 대표 이미지(옵션)
  alt: "Cover Image Alt Text"
pin: true          # true면 홈피드 최상단 고정
toc: true          # true면 본문 Table of Contents 표시
math: false        # 수식 렌더링(KaTeX) 여부
mermaid: false     # mermaid.js 다이어그램 여부
comments: true     # utterances/Giscus 등 댓글 활성화
# lastmod: 2025-08-03 17:30:00 +0900   # 최종 수정일(옵션)
# sitemap:           # sitemap.xml 세부 옵션(없으면 기본값)
#   changefreq: weekly
#   priority: 0.7
---

# Parallel Sequence Modeling via Generalized Spatial Propagation Network

태그: Attention, SPN
Complete?: Yes
링크: https://arxiv.org/pdf/2501.12381
생성 일시: 2025년 6월 6일 오후 5:21

# Abstract

Transformer, Mamba와 같은 기존의 sequence 모델들은 multi-dimensional data를 1D sequence로 처리해 공간적 일관성과 효율성을 저해함.

GSPN은 image에 직접적으로 작용하고 line-scan approach를 통해 dense한 pairwise connection을 생성해 기존 모델이 갖는 제약사항들을 보완함.

# Introduction

Transformer는 quadratic한 연산량과 공간적 일관성을 간과하는 token으로 data를 취급해 vision 작업에서의 적합성을 저해시킴. Transformer에서는 연산량을 줄이기 위해 Linear attention, kernel method을 이용하거나 matrix 곱셈 순서를 변경해 연산량을 감소시키려는 노력을 함.

Mamba의 경우 linear recurrent dynamics를 통해 long-range dependency를 해결하려했으나 두 모델의 방법론 모두 공간적인 정보를 추상화함.

공간적 일관성(spatial coherence) 향상을 위한 하나의 방법은 1D raster scan을 2D line scan으로 확장 즉, 행과 열에 걸쳐 linear propagation을 수행하는 것임. 그러나 이는 누적된 행렬곱 연산이 발생할 우려가 있고 아래와 같은 문제점을 야기함.

- 큰 고유값으로 인한 불안정성, 작은 값으로 인한 정보 소실
- 안정성 위한 weight 감소시 receptive field 감소, long-term dependecy 약화

![image.png](Parallel%20Sequence%20Modeling%20via%20Generalized%20Spatial%2020aad5efe42b80279597c296b78ae06b/image.png)

GSPN은 일관된 attention weight norm을 유지해 2D sequence에서의 stability와 long-range context propagation의 효율성을 갖는 Stability-Context Condition임.

linear line-scan을 통해 행과 열에 걸친 propagation을 병렬화 하여 $\sqrt{N}$ 의 유효 sequence를 갖게 함으로써 계산 효율성을 향상 시킴.

GSPN은 propagation 과정에서 pixel 단위의 weighted sum을 계산함. weight는 input-dependent 하며 learnable하고 pixel 기준으로 이전, 이후 행과 열의 pixel 값을 사용함.

Spatial Propagation Network(SPN)의 개념을 그대로 사용하되 parameter 효율성을 위해 3-way connection을 사용함. 4-direction scan결과를 통합해 완전한 pixel connection 구조

학습가능한 Merger를 도입해 모든 scan 방향에서 집계, image의 구조에 동적으로 적응 가능하도록 함. scan을 통해 position 정보를 inherent 하게 통합하여 position embedding의 필요성 제거, transformer에서 발생하는 `aliasing issues` 회피.

## Related Work

ViT와 더불어 많은 연구에서 2D 데이터를 1D 시퀀스로 평탄화하여 이미지 처리(image processing)를 위해 SSM을 적용함. 이러한 접근 방식은 propagation 과정에서 비선형성의 직접적인 적용을 피하지만, inherent spatial structure 정보를 희생(추상화)할 가능성이 있음.

### SPN

최초 SPN은 CNN 위에 single layer module로 segmentation과 같은 spare-to-dense prediction task를 위해 고안됨.

기존의 SPN은 long-range propagation을 다루지 않으며, ViT와 같은 기본 architecture로의 연구도 진행되지 않음.

GSPN은 아래 개선점을 가짐

- parallel row/col-wise propagation
    - 효율적인 affinity matrix 학습 가능
    - gradient stability 유지
    - long-range correlation 파악

# Method

### 2D Linear Propagation

2D에서의 linear propagation은 sequential row-by-row 또는 column-by-column으로 진행. ($x \in R^{n\times n\times C}$ 가정, row 기준으로 설명함)

$$
h_i^c = w_i^c h_{i-1}^c + \lambda_i^c \odot x_i^c, \quad i \in [1, n-1], c \in [0, C-1]
$$

![image.png](Parallel%20Sequence%20Modeling%20via%20Generalized%20Spatial%2020aad5efe42b80279597c296b78ae06b/image%201.png)

![image.png](Parallel%20Sequence%20Modeling%20via%20Generalized%20Spatial%2020aad5efe42b80279597c296b78ae06b/image%202.png)

- $h \in R^{n \times n \times C}$ : hidden layer
- $h_i$ : i-th hidden state (row)
- $x_i$ : i-th input (row)
- $y_i$ : i-th output

각 channel C는 두 개의 learnable parameter 사용

- c : channel
- $w^c_i \in R^{n \times n}$ : $h^c_{i-i}$에 가중치 부여하는 $n \times n$ 행렬
    - 이전 hidden state를 weighted sum 함
- $\lambda^c_i \in R^n$ : ⊙를 이용해 $x_{ci}$ 를 element-wise로 scale
- 
- $w^c_i \in R^{n \times n}$ : $n \times n$ matrix that weights $h^c_{i-i}$
- $\lambda^c_i \in R^n$ : element-wise scale $x^c_i$ using ⊙

간소화를 위해 Channel을 생략하고 $u_i \in R^n$ 로 요소별 layer 출력을 적용하면 $y_i = u_i \odot h_i$ 과 같음.

### Stability-Context Condition

### Key Implementations for Propagation Layer

Stability-Context Condition을 학습하는 간단한 방법은 pixel 당 *n*개의 출력을 생성하는 $w_{\tau}$를 학습하는 것임. 이는 이전 row의 모든 pixel을 현재 row의 pixel들에 연결하고 weight의 합이 1이 되도록 함. 이러한 연결은 dimension 확장으로 인해 3-way로 연결을 제한한 구조를 제안함. (top-left, top-middle, and top-right pixels in the top-to-bottom propagation direction)

이 결과 $w_{\tau}$는 삼중 대각 행렬이 됨. 그리고 이 삼중 대각 행렬을 곱하면 dense한 $W_{ij}$가 되어 Stability-Context Condition을 위한 요구사항들을 만족함. 또한 4방향의 scan을 통합함으로써 모든 pixel 간의 dense connection을 보장함.

![image.png](Parallel%20Sequence%20Modeling%20via%20Generalized%20Spatial%2020aad5efe42b80279597c296b78ae06b/image%203.png)

# Result